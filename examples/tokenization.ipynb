{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragcar import Ragcar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Available models for tokenization are {'huggingface': ['klue/roberta-large', 'jinmang2/kpfbert', 'MODELS_SUPPORTED(https://huggingface.co/models?library=transformers)'], 'tiktoken': ['cl100k_base', 'p50k_base', 'r50k_base', 'gpt2', 'MODELS_SUPPORTED(https://github.com/openai/tiktoken/blob/main/tiktoken/model.py)'], 'openai': ['gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo', 'MODELS_SUPPORTED(https://platform.openai.com/docs/models)'], 'clova': ['YOUR_MODEL(https://www.ncloud.com/product/aiService/clovaStudio)'], 'kiwi': [None, 'YOUR_MODEL']}([src]: huggingface, [model]: klue/roberta-large, jinmang2/kpfbert, MODELS_SUPPORTED(https://huggingface.co/models?library=transformers)), ([src]: tiktoken, [model]: cl100k_base, p50k_base, r50k_base, gpt2, MODELS_SUPPORTED(https://github.com/openai/tiktoken/blob/main/tiktoken/model.py)), ([src]: openai, [model]: gpt-4-turbo, gpt-4, gpt-3.5-turbo, MODELS_SUPPORTED(https://platform.openai.com/docs/models)), ([src]: clova, [model]: YOUR_MODEL(https://www.ncloud.com/product/aiService/clovaStudio)), ([src]: kiwi, [model]: None, YOUR_MODEL)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ragcar.available_models(\"tokenization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hugging Face ğŸ¤—](https://huggingface.co/models?library=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ë„¤ì´ë²„',\n",
       " '\"',\n",
       " 'í•˜ì´í¼',\n",
       " '##í´ë¡œ',\n",
       " '##ë°”',\n",
       " '##X',\n",
       " ',',\n",
       " 'í•œêµ­ì–´',\n",
       " 'ì—­ëŸ‰',\n",
       " '##ì€',\n",
       " 'ë¹…',\n",
       " '##í…Œí¬',\n",
       " 'AI',\n",
       " '##ë³´',\n",
       " '##ë‹¤',\n",
       " 'ë›°ì–´ë‚˜',\n",
       " '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"huggingface\", model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â–ë„¤ì´ë²„',\n",
       " 'â–\"',\n",
       " 'í•˜ì´',\n",
       " 'í¼',\n",
       " 'í´',\n",
       " 'ë¡œ',\n",
       " 'ë°”',\n",
       " 'X',\n",
       " ',',\n",
       " 'â–í•œêµ­ì–´',\n",
       " 'â–ì—­',\n",
       " 'ëŸ‰',\n",
       " 'ì€',\n",
       " 'â–',\n",
       " 'ë¹…',\n",
       " 'í…Œí¬',\n",
       " 'â–AI',\n",
       " 'ë³´ë‹¤',\n",
       " 'â–ë›°ì–´',\n",
       " 'ë‚˜',\n",
       " '\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tiktoken](https://github.com/openai/tiktoken/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"tiktoken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xeb\\xb2\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95\\x98',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\xa1\\x9c',\n",
       " b'\\xeb\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' \\xed\\x95\\x9c',\n",
       " b'\\xea\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b' \\xec\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85\\x8c',\n",
       " b'\\xed\\x81\\xac',\n",
       " b' AI',\n",
       " b'\\xeb\\xb3\\xb4',\n",
       " b'\\xeb\\x8b\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b'\\xeb\\x82\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"tiktoken\", model=\"p50k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb',\n",
       " b'\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xb2',\n",
       " b'\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95',\n",
       " b'\\x98',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xa1',\n",
       " b'\\x9c',\n",
       " b'\\xeb',\n",
       " b'\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' ',\n",
       " b'\\xed\\x95',\n",
       " b'\\x9c',\n",
       " b'\\xea',\n",
       " b'\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b' \\xec',\n",
       " b'\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb',\n",
       " b'\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d',\n",
       " b'\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85',\n",
       " b'\\x8c',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xac',\n",
       " b' AI',\n",
       " b'\\xeb',\n",
       " b'\\xb3',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\x8b',\n",
       " b'\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\x82',\n",
       " b'\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OpenAI](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xeb\\xb2\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95\\x98',\n",
       " b'\\xec\\x9d\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\xa1\\x9c',\n",
       " b'\\xeb\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' \\xed\\x95\\x9c',\n",
       " b'\\xea\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b' \\xec\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85\\x8c',\n",
       " b'\\xed\\x81\\xac',\n",
       " b' AI',\n",
       " b'\\xeb\\xb3\\xb4',\n",
       " b'\\xeb\\x8b\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec\\x96\\xb4',\n",
       " b'\\xeb\\x82\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"openai\", model=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xeb',\n",
       " b'\\x84',\n",
       " b'\\xa4',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xb2',\n",
       " b'\\x84',\n",
       " b' \"',\n",
       " b'\\xed\\x95',\n",
       " b'\\x98',\n",
       " b'\\xec\\x9d',\n",
       " b'\\xb4',\n",
       " b'\\xed',\n",
       " b'\\x8d',\n",
       " b'\\xbc',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\xa1',\n",
       " b'\\x9c',\n",
       " b'\\xeb',\n",
       " b'\\xb0',\n",
       " b'\\x94',\n",
       " b'X',\n",
       " b',',\n",
       " b' ',\n",
       " b'\\xed\\x95',\n",
       " b'\\x9c',\n",
       " b'\\xea',\n",
       " b'\\xb5',\n",
       " b'\\xad',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b' \\xec',\n",
       " b'\\x97',\n",
       " b'\\xad',\n",
       " b'\\xeb',\n",
       " b'\\x9f',\n",
       " b'\\x89',\n",
       " b'\\xec\\x9d',\n",
       " b'\\x80',\n",
       " b' \\xeb',\n",
       " b'\\xb9',\n",
       " b'\\x85',\n",
       " b'\\xed',\n",
       " b'\\x85',\n",
       " b'\\x8c',\n",
       " b'\\xed',\n",
       " b'\\x81',\n",
       " b'\\xac',\n",
       " b' AI',\n",
       " b'\\xeb',\n",
       " b'\\xb3',\n",
       " b'\\xb4',\n",
       " b'\\xeb\\x8b',\n",
       " b'\\xa4',\n",
       " b' \\xeb',\n",
       " b'\\x9b',\n",
       " b'\\xb0',\n",
       " b'\\xec',\n",
       " b'\\x96',\n",
       " b'\\xb4',\n",
       " b'\\xeb',\n",
       " b'\\x82',\n",
       " b'\\x98',\n",
       " b'\"']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperCLOVA ëª¨ë¸\n",
    "`.env` íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ `X-NCP-APIGW-API-KEY`, `X-NCP-CLOVASTUDIO-API-KEY`ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ë‹¤ìŒê³¼ ê°™ì´ ì§ì ‘ ë³€ìˆ˜ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. \n",
    "HyperCLOVA API ì‚¬ìš©ë°©ë²•ì€ [ì—¬ê¸°ì„œ](https://guide.ncloud-docs.com/docs/clovastudio-explorer03) ì°¸ê³ í•´ì£¼ì„¸ìš”.\n",
    "* model_n: API URL\n",
    "* api_key: X-NCP-APIGW-API-KEY\n",
    "* app_key: X-NCP-CLOVASTUDIO-API-KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(\n",
    "    tool=\"tokenization\", \n",
    "    src=\"clova\",\n",
    "    model=\"https://clovastudio.apigw.ntruss.com/testapp/v1/api-tools/chat-tokenize/HCX-003/{}\".format(os.getenv('TOKENIZE_HCX_APP_ID'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(\n",
    "    tool=\"tokenization\", \n",
    "    src=\"clova\",\n",
    "    model={\n",
    "        \"model_n\": \"https://clovastudio.apigw.ntruss.com/testapp/v1/api-tools/tokenize/LK-D2/{}\".format(os.getenv('TOKENIZE_APP_ID')),\n",
    "        \"api_key\": os.getenv('X-NCP-APIGW-API-KEY'),\n",
    "        \"app_key\": os.getenv('X-NCP-CLOVASTUDIO-API-KEY')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Kiwipiepy](https://github.com/bab2min/kiwipiepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Ragcar(tool=\"tokenization\", src=\"kiwi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(form='ë„¤ì´ë²„', tag='NNP', start=0, len=3),\n",
       " Token(form='\"', tag='SSO', start=4, len=1),\n",
       " Token(form='í•˜ì´í¼í´ë¡œë°”', tag='NNG', start=5, len=6),\n",
       " Token(form='X', tag='SL', start=11, len=1),\n",
       " Token(form=',', tag='SP', start=12, len=1),\n",
       " Token(form='í•œêµ­ì–´', tag='NNP', start=14, len=3),\n",
       " Token(form='ì—­ëŸ‰', tag='NNG', start=18, len=2),\n",
       " Token(form='ì€', tag='JX', start=20, len=1),\n",
       " Token(form='ë¹…', tag='NNG', start=22, len=1),\n",
       " Token(form='í…Œí¬', tag='NNG', start=23, len=2),\n",
       " Token(form='AI', tag='SL', start=26, len=2),\n",
       " Token(form='ë³´ë‹¤', tag='JKB', start=28, len=2),\n",
       " Token(form='ë›°ì–´ë‚˜', tag='VA', start=31, len=3),\n",
       " Token(form='ì–´', tag='EF', start=33, len=1),\n",
       " Token(form='\"', tag='SSC', start=34, len=1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(form='ë„¤ì´ë²„', tag='NNP', start=0, len=3),\n",
       " Token(form='\"', tag='SSO', start=4, len=1),\n",
       " Token(form='í•˜ì´í¼í´ë¡œë°”X', tag='NNP', start=5, len=7),\n",
       " Token(form=',', tag='SP', start=12, len=1),\n",
       " Token(form='í•œêµ­ì–´', tag='NNP', start=14, len=3),\n",
       " Token(form='ì—­ëŸ‰', tag='NNG', start=18, len=2),\n",
       " Token(form='ì€', tag='JX', start=20, len=1),\n",
       " Token(form='ë¹…', tag='NNG', start=22, len=1),\n",
       " Token(form='í…Œí¬', tag='NNG', start=23, len=2),\n",
       " Token(form='AI', tag='SL', start=26, len=2),\n",
       " Token(form='ë³´ë‹¤', tag='JKB', start=28, len=2),\n",
       " Token(form='ë›°ì–´ë‚˜', tag='VA', start=31, len=3),\n",
       " Token(form='ì–´', tag='EF', start=33, len=1),\n",
       " Token(form='\"', tag='SSC', start=34, len=1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the file in write mode\n",
    "with open('user_dict_sample.txt', 'w') as f:\n",
    "    # Write the string to the file\n",
    "    f.write('í•˜ì´í¼í´ë¡œë°”X\\tNNP\\t1.0\\n')\n",
    "\n",
    "user_tokenizer = Ragcar(tool=\"tokenization\", src=\"kiwi\", model=\"user_dict_sample.txt\")\n",
    "\n",
    "user_tokenizer('ë„¤ì´ë²„ \"í•˜ì´í¼í´ë¡œë°”X, í•œêµ­ì–´ ì—­ëŸ‰ì€ ë¹…í…Œí¬ AIë³´ë‹¤ ë›°ì–´ë‚˜\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a545914905f7133bd9391d6777e0ef03369109a34050a83c08d63903eaf0a072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
